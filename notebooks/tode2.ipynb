{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ordinary-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def assign(self,args):\n",
    "        for key, val in args.items():\n",
    "            if key != 'self':\n",
    "                setattr(self, key, val)\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "announced-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transfer_ode as tode\n",
    "ADJOINT = False\n",
    "if ADJOINT:\n",
    "    from torchdiffeq import odeint_adjoint as odeint\n",
    "else:\n",
    "    from torchdiffeq import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifty-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "def assign_args(args_):\n",
    "    for arg, val in args_.items():\n",
    "        fs = []\n",
    "        for f in globals().values():\n",
    "            if type(f) == types.FunctionType:\n",
    "                #print(f)\n",
    "                try:\n",
    "                    #print(f.args)\n",
    "                    f.args = args\n",
    "                except:\n",
    "                    fs.append(f)\n",
    "                    \n",
    "                    #print(f'f, {id(f)}')\n",
    "        for f in fs:\n",
    "            #print(f'f, {id(f)}')\n",
    "            f.__globals__[arg] = val\n",
    "                    #f.__globals__[\"NDIMZ\"] = args.hidden_size\n",
    "def assign_vars(func, key, val):\n",
    "    func.__globals__[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "basic-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.viz:\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     fig = plt.figure(figsize=(12, 4), facecolor='white')\n",
    "#     ax_traj = fig.add_subplot(131, frameon=False)\n",
    "#     ax_phase = fig.add_subplot(132, frameon=False)\n",
    "#     ax_vecfield = fig.add_subplot(133, frameon=False)\n",
    "#     plt.show(block=False)\n",
    "# if __name__ == '__main__':\n",
    "scaler = MinMaxScaler()\n",
    "def optimize(a0 = lambda t: t**2,#-(5./t + t)#-3*t**2\n",
    "             a1 = lambda t:1 + 0.*t,\n",
    "             f = lambda t: torch.sin(t),#t**6#3*t**2#torch.sin(t)\n",
    "             ics = torch.tensor(np.arange(-7.5, 7.5, 0.25), dtype = torch.float32),#torch.linspace(-7.,7.,200),\n",
    "             method : str = \"dopri5\", \n",
    "             tmax : float = 5,\n",
    "             #dt   : int   = 0.01,\n",
    "             method_rc: str = \"euler\",\n",
    "             wout : str = \"analytic\",\n",
    "             paramg : str = \"lin\",\n",
    "             niters : int = 100,\n",
    "             hidden_size : int = 200,\n",
    "             viz = False,#'store_false',\n",
    "             gpu : int = 0,\n",
    "             adjoint = 'store_false',\n",
    "             random_sampling = True,\n",
    "             n_timepoints = 50,\n",
    "             regularization = 0,\n",
    "             l1_reg_strength = 0,\n",
    "             #visualize_ = False,\n",
    "             niters_test: int =15000,\n",
    "             num_bundles: int= 20,\n",
    "             num_bundles_test : int =20,\n",
    "             test_freq :int =100,\n",
    "             evaluate_only : bool = False,\n",
    "             bias_at_inference : bool = False,\n",
    "             ffnn_bias: bool = False,\n",
    "             force_bias : int  = 0\n",
    "            ):\n",
    "    args = Args()\n",
    "    \n",
    "    args.assign(locals())\n",
    "    tode.args = args\n",
    "    \n",
    "    if args.wout == 'analytic':\n",
    "        wout_gen = tode.Transformer_Analytic(regularization, bias_at_inference)\n",
    "        #wout_gen = tode.Transformer_Analytic(a0, a1, f, regularization)\n",
    "        \n",
    "        \n",
    "    \n",
    "    dt=tmax/n_timepoints\n",
    "    args.dt = dt\n",
    "    \n",
    "    if not random_sampling:\n",
    "        t = torch.arange(0.,args.tmax,args.dt)\n",
    "    else:\n",
    "        t = torch.rand(n_timepoints) *tmax\n",
    "        t = t.sort().values\n",
    "    \n",
    "    t = t.reshape(-1,1)\n",
    "    \n",
    "    #assign_vars(tode.compute_s_sdot, \"t\", t)\n",
    "    assign_args({\"t\": t})\n",
    "    \n",
    "    \n",
    "    globals()[\"args\"] = args\n",
    "    \n",
    "    ii = 0\n",
    "    NDIMZ = args.hidden_size\n",
    "    # define coefficients as lambda functions, used for gt and wout_analytic\n",
    "    # training differential equation\n",
    "\n",
    "    #need to sample tuple of (a1,f,IC)\n",
    "    # each column of Wouts defines a solution thus, each tuple defines a solution too\n",
    "\n",
    "\n",
    "    f_train = [lambda t: torch.cos(t) + force_bias,\n",
    "               lambda t: torch.cos(t) - force_bias,\n",
    "               lambda t: torch.sin(t) - force_bias, \n",
    "               lambda t: torch.sin(t) + force_bias, \n",
    "               lambda t: torch.sin(t)* torch.cos(t) - force_bias,\n",
    "               lambda t: torch.sin(t)* torch.cos(t) + force_bias]\n",
    "    a0_train = [lambda t:t**2]\n",
    "    r1 = -10.\n",
    "    r2 = 10.\n",
    "    true_y0 = (r2 - r1) * torch.rand(100) + r1\n",
    "    t = torch.arange(0., args.tmax, args.dt).reshape(-1, 1)\n",
    "    t.requires_grad = True\n",
    "\n",
    "    # sample each parameter to build the tuples\n",
    "    f_samples = random.choices(f_train, k=args.num_bundles)\n",
    "    a0_samples = random.choices(a0_train, k=args.num_bundles)\n",
    "    y0_samples = torch.tensor(random.choices(true_y0, k=args.num_bundles)).reshape(1,-1)\n",
    "\n",
    "    diffeq_init = tode.diffeq(a0_samples,f_samples)\n",
    "    gt_generator = tode.base_diffeq(diffeq_init)\n",
    "    true_y = gt_generator.get_solution(y0_samples,t.ravel()).reshape(-1,args.num_bundles)\n",
    "\n",
    "    # use this quick test to find gt solutions and check training ICs\n",
    "    # have a solution (don't blow up for dopri5 integrator)\n",
    "    # true_y = gt_generator.get_solution(true_y0.reshape(-1, 1), t.ravel())\n",
    "\n",
    "    # instantiate wout with coefficients\n",
    "    func = tode.ODEFunc(hidden_dim=NDIMZ, output_dim=args.num_bundles, calc_bias = ffnn_bias)\n",
    "\n",
    "    optimizer = optim.Adam(func.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "    \n",
    "    \n",
    "\n",
    "    loss_collector = []\n",
    "    \n",
    "    assign_vars(tode.visualize,\"args\", args)\n",
    "\n",
    "    if not args.evaluate_only:\n",
    "\n",
    "        for itr in range(1, args.niters + 1):\n",
    "            func.train()\n",
    "\n",
    "            # add t0 to training times, including randomly generated ts\n",
    "            t0 = torch.tensor([[0.]])\n",
    "            t0.requires_grad = True\n",
    "            tv = args.tmax * torch.rand(int(args.tmax / args.dt)).reshape(-1, 1)\n",
    "            tv.requires_grad = True\n",
    "            tv = torch.cat([t0, tv], 0)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute hwout,hdotwout\n",
    "            pred_y = func(tv)\n",
    "            pred_ydot = tode.diff(pred_y, tv)\n",
    "            \n",
    "            \n",
    "\n",
    "            # enforce diffeq\n",
    "            loss_diffeq = pred_ydot - tode.get_udot(tv,pred_y,a0_samples,f_samples)\n",
    "            # loss_diffeq = (a1(tv.detach()).reshape(-1, 1)) * pred_ydot + (a0(tv.detach()).reshape(-1, 1)) * pred_y - f(\n",
    "            #     tv.detach()).reshape(-1, 1)\n",
    "\n",
    "            # enforce initial conditions\n",
    "            loss_ics = pred_y[0, :].ravel() - y0_samples.ravel()\n",
    "\n",
    "            loss = torch.mean(torch.square(loss_diffeq)) + torch.mean(torch.square(loss_ics))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_collector.append(torch.square(loss_diffeq).mean().item())\n",
    "            if itr % args.test_freq == 0:\n",
    "                func.eval()\n",
    "                pred_y = func(t).detach()\n",
    "                pred_y = pred_y.reshape(-1, args.num_bundles)\n",
    "                tode.visualize(true_y.detach(), pred_y.detach(), loss_collector)\n",
    "                ii += 1\n",
    "\n",
    "        torch.save(func.state_dict(), 'func_ffnn_bundles')\n",
    "\n",
    "    # with torch.no_grad():\n",
    "\n",
    "    f_test = [lambda t: torch.sin(t)]\n",
    "    a0_test = [lambda t: t**3]\n",
    "    r1 = -15.\n",
    "    r2 = 15.\n",
    "    true_y0 = (r2 - r1) * torch.rand(100) + r1\n",
    "    t = torch.arange(0., args.tmax, args.dt).reshape(-1, 1)\n",
    "    t.requires_grad = True\n",
    "\n",
    "    # sample each parameter to build the tuples\n",
    "    f_samples = random.choices(f_test, k=args.num_bundles_test)\n",
    "    a0_samples = random.choices(a0_test, k=args.num_bundles_test)\n",
    "    y0_samples = torch.tensor(random.choices(true_y0, k=args.num_bundles_test)).reshape(1, -1)\n",
    "\n",
    "    # print(y0_samples.shape)\n",
    "    diffeq_init = tode.diffeq(a0_samples, f_samples)\n",
    "    gt_generator = tode.base_diffeq(diffeq_init)\n",
    "\n",
    "\n",
    "    func.load_state_dict(torch.load('func_ffnn_bundles'))\n",
    "    func.eval()\n",
    "\n",
    "    h = func.h(t)\n",
    "    hd = tode.diff(h, t)\n",
    "    h = h.detach()\n",
    "    hd = hd.detach()\n",
    "\n",
    "    gz_np = h.detach().numpy()\n",
    "    T = np.linspace(0, 1, len(gz_np)) ** 2\n",
    "    new_hiddens = scaler.fit_transform(gz_np)\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_comps = pca.fit_transform(new_hiddens)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    if pca_comps.shape[1] >= 2:\n",
    "        s = 10  # Segment length\n",
    "        for i in range(0, len(gz_np) - s, s):\n",
    "            ax.plot3D(pca_comps[i:i + s + 1, 0], pca_comps[i:i + s + 1, 1], pca_comps[i:i + s + 1, 2],\n",
    "                      color=(0.1, 0.8, T[i]))\n",
    "            plt.xlabel('comp1')\n",
    "            plt.ylabel('comp2')\n",
    "\n",
    "\n",
    "    s1 = time.time()\n",
    "    \n",
    "    wout, bias = wout_gen.get_wout(h, hd, y0_samples, t.detach(), a0_samples[0], f_samples)\n",
    "    #wout = tode.get_wout(h, hd, y0_samples, t.detach(),a0_samples[0],f_samples)\n",
    "    pred_y = h @ wout + bias\n",
    "    s2 = time.time()\n",
    "    print(f'all_ics:{s2 - s1}')\n",
    "\n",
    "    s1 = time.time()\n",
    "    true_ys = (gt_generator.get_solution(y0_samples, t.ravel())).reshape(-1, args.num_bundles_test)\n",
    "    s2 = time.time()\n",
    "    print(f'gt_ics:{s2 - s1}')\n",
    "\n",
    "    print(true_ys.shape,pred_y.shape)\n",
    "\n",
    "    # s1 = time.time()\n",
    "    # true_y = estim_generator.get_solution(ics.reshape(-1, 1), t.ravel())\n",
    "    # estim_ys = true_y.reshape(len(pred_y), ics.shape[1])\n",
    "    # s2 = time.time()\n",
    "    # print(f'estim_ics:{s2 - s1}')\n",
    "\n",
    "    # print(f'prediction_accuracy:{((pred_y - true_ys) ** 2).mean()} pm {((pred_y - true_ys) ** 2).std()}')\n",
    "    # print(f'estim_accuracy:{((estim_ys - true_ys) ** 2).mean()} pm {((estim_ys - true_ys) ** 2).std()}')\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "    # print(true_ys[0,:])\n",
    "    for i in range(0, args.num_bundles_test, 50):\n",
    "        gt = true_ys.cpu().numpy()[:, i]\n",
    "        preds = pred_y.cpu().numpy()[:, i]\n",
    "        ax[0].plot(t.detach().cpu().numpy(), gt, c='blue', linestyle='dashed')\n",
    "        ax[0].plot(t.detach().cpu().numpy(),  preds , c='orange')\n",
    "        # plt.draw()\n",
    "\n",
    "    ax[1].plot(t.detach().cpu().numpy(), ((true_ys - pred_y) ** 2).mean(1).cpu().numpy(), c='green')\n",
    "    ax[1].set_xlabel('Time (s)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    prediction_residuals = ((pred_y - true_ys) ** 2)\n",
    "    #estimation_residuals = ((estim_ys - true_ys) ** 2)\n",
    "    score = prediction_residuals.mean()\n",
    "    return score, pred_y, true_y#, estim_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "correct-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_args = {\"a0\" : lambda t: t**2,#-(5./t + t)#-3*t**2\n",
    "               \"a1\" : lambda t:1 + 0.*t,\n",
    "               \"f\" : lambda t: torch.sin(t),\n",
    "               \"num_bundles\" : 400}\n",
    "               #\"n_timepoints\" : 30}\n",
    "    \n",
    "no_bias = {\"bias_at_inference\" : False, \n",
    "           \"ffnn_bias\" : True, **shared_args}\n",
    "\n",
    "bias = {\"bias_at_inference\" : True, \n",
    "           \"ffnn_bias\" : True, **shared_args}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-queen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_bias = np.array(range(21) )-10\n",
    "b_results = []\n",
    "nb_results = []\n",
    "\n",
    "for f in force_bias:\n",
    "    nb_results.append(optimize(**no_bias,\n",
    "                               force_bias = f,\n",
    "                               n_timepoints = 50))\n",
    "    b_results.append(optimize(**bias, \n",
    "                                 force_bias = f,\n",
    "                                 n_timepoints = 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_scores = [{\"score\":float(result[0]), \"n\" :n_timepoints[i], \"bias\" : True} for i, result in enumerate(b_results)]\n",
    "nb_scores = [{\"score\":float(result[0]), \"n\" :n_timepoints[i], \"bias\" : False} for i, result in enumerate(nb_results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(b_scores + nb_scores)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = df,x = \"n\", y = \"score\", hue = \"bias\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"n_timpoints\")\n",
    "plt.ylabel(\"score (MSE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# losses_l1 = []\n",
    "# for l1 in [0.0001, 0.001, 0.01, 0.1, 0]:\n",
    "#     score, pred, gt = optimize(a0 = lambda t: t**2,#-(5./t + t)#-3*t**2\n",
    "#                                 a1 = lambda t:1 + 0.*t,\n",
    "#                                 f = lambda t: torch.sin(t),\n",
    "#                                 n_timepoints = 100,\n",
    "#                                 regularization = 1)\n",
    "#                                 #l1_reg_strength = l1)\n",
    "#     data_point = {\"score\" : float(score), \"l1_reg\" : l1}\n",
    "#     losses_l1.append(data_point) #[str(l1)] = (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-alias",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
