{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tracked-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transfer_ode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offshore-techno",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchdiffeq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-236273774010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdiffeq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0modeint_adjoint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0modeint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchdiffeq'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def assign(self,args):\n",
    "        for key, val in args.items():\n",
    "            if key != 'self':\n",
    "                setattr(self, key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transfer_ode as tode\n",
    "#tode.odeint = odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJOINT = False\n",
    "if ADJOINT:\n",
    "    from torchdiffeq import odeint_adjoint as odeint\n",
    "else:\n",
    "    from torchdiffeq import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "def assign_args(args_):\n",
    "    for arg, val in args_.items():\n",
    "        fs = []\n",
    "        for f in globals().values():\n",
    "            if type(f) == types.FunctionType:\n",
    "                #print(f)\n",
    "                try:\n",
    "                    #print(f.args)\n",
    "                    f.args = args\n",
    "                except:\n",
    "                    fs.append(f)\n",
    "                    \n",
    "                    #print(f'f, {id(f)}')\n",
    "        for f in fs:\n",
    "            #print(f'f, {id(f)}')\n",
    "            f.__globals__[arg] = val\n",
    "                    #f.__globals__[\"NDIMZ\"] = args.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign_args({\"hu\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys,os,argparse\n",
    "# from IPython.display import HTML\n",
    "# CONFIG_FILE = '.config_ipynb'\n",
    "# if os.path.isfile(CONFIG_FILE):\n",
    "#     with open(CONFIG_FILE) as f:\n",
    "#         sys.argv = f.read().split()\n",
    "# else:\n",
    "#     sys.argv = ['test_args.py', 'input_file', '--int_param', '12']\n",
    "\n",
    "# parser = argparse.ArgumentParser('NeuralODE transfer demo')\n",
    "# parser.add_argument('--method', type=str, choices=['dopri5', 'adams'], default='dopri5')\n",
    "# parser.add_argument('--tmax', type=float, default=5.)\n",
    "# parser.add_argument('--dt', type=int, default=0.1)\n",
    "\n",
    "# parser.add_argument('--method_rc', type=str, choices=['euler'], default='euler')\n",
    "# parser.add_argument('--wout', type=str, default='analytic')\n",
    "# parser.add_argument('--paramg', type=str, default='lin')\n",
    "\n",
    "# parser.add_argument('--niters', type=int, default=100)\n",
    "# parser.add_argument('--hidden_size', type=int, default=200)\n",
    "\n",
    "# parser.add_argument('--test_freq', type=int, default=1)\n",
    "\n",
    "# parser.add_argument('--viz', action='store_false')\n",
    "# parser.add_argument('--gpu', type=int, default=0)\n",
    "# parser.add_argument('--adjoint', action='store_false')\n",
    "# args = parser.parse_args()\n",
    "# p = args.int_param\n",
    "# print(args.input_file,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_vars(func, key, val):\n",
    "    func.__globals__[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-retro",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinOut(args, wout_gen, s, sd, true_y0, t):\n",
    "    \n",
    "    if args.wout == \"analytic\":\n",
    "        \n",
    "        wout, bias = wout_gen.get_wout(s.detach(),sd.detach(), true_y0, t)\n",
    "    \n",
    "    elif args.wout == \"learned\":\n",
    "        \n",
    "        wout, bias = wout_gen.get_wout()\n",
    "        \n",
    "    return wout, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(a0 = lambda t: t**2,#-(5./t + t)#-3*t**2\n",
    "             a1 = lambda t:1 + 0.*t,\n",
    "             f = lambda t: torch.sin(t),#t**6#3*t**2#torch.sin(t)\n",
    "             ics = torch.tensor(np.arange(-2, 2.9, 0.25), dtype = torch.float32),#torch.linspace(-7.,7.,200),\n",
    "             method : str = \"dopri5\", \n",
    "             tmax : float = 5,\n",
    "             #dt   : int   = 0.01,\n",
    "             method_rc: str = \"euler\",\n",
    "             wout : str = \"analytic\",\n",
    "             paramg : str = \"lin\",\n",
    "             niters : int = 100,\n",
    "             hidden_size : int = 200,\n",
    "             test_freq : int = 1,\n",
    "             viz = False,#'store_false',\n",
    "             gpu : int = 0,\n",
    "             adjoint = 'store_false',\n",
    "             random_sampling = True,\n",
    "             n_timepoints = 50,\n",
    "             regularization = 700,\n",
    "             l1_reg_strength = 0\n",
    "            ):\n",
    "    args = Args()\n",
    "    \n",
    "    args.assign(locals())\n",
    "    tode.args = args\n",
    "    #assign_args({\"args\": args})\n",
    "    \n",
    "    dt=tmax/n_timepoints\n",
    "    \n",
    "    \n",
    "    globals()[\"args\"] = args\n",
    "    \n",
    "    print(args)\n",
    "    ii = 0\n",
    "    NDIMZ = args.hidden_size\n",
    "    \n",
    "    \n",
    "    assign_vars(tode.compute_s_sdot, \"args\", args)\n",
    "    assign_vars(tode.compute_s_sdot, \"NDIMZ\", NDIMZ)\n",
    "    \n",
    "    \n",
    "    #tode.args = args\n",
    "    \n",
    "    \n",
    "    #assign_args({\"NDIMZ\": NDIMZ})\n",
    "    \n",
    "    # define coefficients as lambda functions, used for gt and wout_analytic\n",
    "    \n",
    "\n",
    "    diffeq_init = tode.diffeq(a0,a1,f)\n",
    "    gt_generator = tode.base_diffeq(diffeq_init)\n",
    "    estim_generator = tode.estim_diffeq(diffeq_init)\n",
    "    true_y0 = torch.tensor([[5.]])\n",
    "    if not random_sampling:\n",
    "        t = torch.arange(0.,args.tmax,args.dt)\n",
    "    else:\n",
    "        t = torch.rand(n_timepoints) *tmax\n",
    "        t = t.sort().values\n",
    "    \n",
    "    t = t.reshape(-1,1)\n",
    "    \n",
    "    assign_vars(tode.compute_s_sdot, \"t\", t)\n",
    "    assign_args({\"t\": t})\n",
    "\n",
    "    true_y = gt_generator.get_solution(true_y0,t.ravel())\n",
    "\n",
    "    # wout generator\n",
    "    if args.wout == 'analytic':\n",
    "        wout_gen = tode.Transformer_Analytic(a0, a1, f, regularization)\n",
    "    elif args.wout == 'learned':\n",
    "        #optimizer = optim.Adam(func.parameters(),lr=1e-5)\n",
    "        wout_gen = tode.Transformer_Learned(NDIMZ, true_y0.shape[1])\n",
    "    \n",
    "    # hidden state generator\n",
    "    func = tode.ODEFunc(NDIMZ)\n",
    "    # func.upper.weight\n",
    "\n",
    "    #if args.wout  == 'analytic':\n",
    "    optimizer = optim.Adam(func.parameters(),lr=1e-5)\n",
    "    #     elif args.wout == 'learned':\n",
    "    #         optimizer = optim.Adam(func.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "    #     #     optimizer = optim.SGD([\n",
    "    #         {'params': func.parameters()},\n",
    "    #         {'params': wout_gen.parameters(), 'lr': 1e-4, 'weight_decay': 1e-3}\n",
    "    #     ], lr=1e-3)\n",
    "\n",
    "\n",
    "    # true_y0 = torch.tensor([[3.]])\n",
    "    param = tode.Parametrization(args.paramg)\n",
    "    zinit_ = torch.ones(NDIMZ).reshape(1, NDIMZ)\n",
    "    loss_collector = []\n",
    "    for itr in range(1, args.niters + 1):\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        zinit = func.get_z0(zinit_)\n",
    "        #print(f'f, {id(tode.compute_s_sdot)}')\n",
    "        s,sd = tode.compute_s_sdot(func,zinit,t,param)\n",
    "        \n",
    "        # print(s[0],sd[0])\n",
    "        # if (itr-1)%200==0:\n",
    "        wout, bias = wout_gen.get_wout(s.detach(),sd.detach(), true_y0, t)\n",
    "        #print(f'bias: {bias}')\n",
    "\n",
    "        # wout = torch.ones(100,1)\n",
    "        # wout = wout_gen.get_wout(s.detach(), sd.detach(), true_y0, t)\n",
    "        # print(wout)\n",
    "        # wout = wout.detach()\n",
    "\n",
    "        pred_y = true_y0 + torch.mm(s, wout) + bias\n",
    "        pred_ydot = torch.mm(sd, wout)\n",
    "        lst = (a1(t).reshape(-1,1))*pred_ydot + (a0(t).reshape(-1,1))*pred_y - f(t).reshape(-1,1)\n",
    "        # lst = wout-1.\n",
    "        # l2_reg = None\n",
    "        l1_reg = torch.linalg.norm(wout.abs())\n",
    "\n",
    "        # for name,paramss in func.named_parameters():\n",
    "        #     if name == 'upper.weight':\n",
    "        #         # print(paramss)\n",
    "        #         l2_reg = torch.sum(torch.abs(paramss))\n",
    "        # print(func.upper.weight.detach().cpu().numpy())\n",
    "        # print(l2_reg)\n",
    "        loss = torch.mean(torch.square(lst)) + l1*l1_reg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_collector.append(torch.square(lst).mean().item())\n",
    "        if itr % args.test_freq == 0:\n",
    "            # print(loss.item())\n",
    "            with torch.no_grad():\n",
    "                #print(f'f, {id(tode.compute_s_sdot)}')\n",
    "                s, sd = tode.compute_s_sdot(func, zinit, t, param)\n",
    "                \n",
    "\n",
    "                wout, bias = wout_gen.get_wout(s, sd, true_y0, t)\n",
    "                #     # wout = torch.ones(100, 1)\n",
    "                #\n",
    "                # elif args.wout == 'learned':\n",
    "                #     wout = wout_gen.get_wout()\n",
    "\n",
    "                pred_y = true_y0[0,0].reshape(1, 1) + torch.mm(s, wout)[:,0] + bias\n",
    "                pred_y = pred_y.reshape(-1,1,1)\n",
    "                # loss = torch.mean(torch.abs(pred_y - true_y))\n",
    "                # print('Iter {:04d} | Total Loss {:.6f}'.format(itr, loss.item()))\n",
    "                tode.visualize(true_y, pred_y, func, ii,loss_collector,s)\n",
    "                ii += 1\n",
    "\n",
    "\n",
    "\n",
    "        # torch.save(func.state_dict(), 'func_dict_wout')\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        s, sd = tode.compute_s_sdot(func, zinit, t, param)\n",
    "        #inference for other ICs\n",
    "        #ics = torch.linspace(-7.,7.,200)\n",
    "\n",
    "\n",
    "        # results_df = np.zeros((len(ics),6))\n",
    "        y0 = ics.reshape(1,-1)\n",
    "        s1 = time.time()\n",
    "        wout, bias = wout_gen.get_wout(s, sd, y0, t)\n",
    "        pred_y = y0 + torch.mm(s, wout) + bias\n",
    "        s2 = time.time()\n",
    "        print(f'all_ics:{s2-s1}')\n",
    "\n",
    "        \n",
    "        rmsr = 0.\n",
    "        true_ys= torch.zeros(len(pred_y),len(ics))\n",
    "        estim_ys = torch.zeros(len(pred_y), len(ics))\n",
    "        # print(true_ys.shape)\n",
    "        s1 = time.time()\n",
    "        # y0 = ic.reshape(1,1)\n",
    "        true_y = gt_generator.get_solution(y0.reshape(-1,1),t.ravel())\n",
    "        true_ys = true_y.reshape(len(pred_y),len(ics))\n",
    "        s2 = time.time()\n",
    "        print(f'gt_ics:{s2 - s1}')\n",
    "\n",
    "        s1 = time.time()\n",
    "        # for ic_index, ic in enumerate(ics):\n",
    "        #     y0 = ic.reshape(1, 1)\n",
    "        true_y = estim_generator.get_solution(y0.reshape(-1,1), t.ravel())\n",
    "        estim_ys = true_y.reshape(len(pred_y),len(ics))\n",
    "        s2 = time.time()\n",
    "        \n",
    "        prediction_residuals = ((pred_y - true_ys) ** 2)\n",
    "        estimation_residuals = ((estim_ys - true_ys) ** 2)\n",
    "        \n",
    "        #print(f'estim_ics:{s2 - s1}')\n",
    "        print(f'prediction mse:{prediction_residuals.mean()} pm {prediction_residuals.std()}')\n",
    "        #print(f'estim mse {estimation_residuals.mean()} pm {estimation_residuals.std()}')\n",
    "        visualize_ = False\n",
    "        if visualize_:\n",
    "            fig,ax = plt.subplots(1,3,figsize=(15,4))\n",
    "            plt.sca(ax[0])\n",
    "            pred, gt, estim = pred_y, true_ys, estim_ys\n",
    "            plt.plot(gt, alpha = 0.3, color = \"red\")\n",
    "            plt.plot(pred, alpha = 0.3, color = \"blue\")\n",
    "            #plt.plot(estim, alpha = 0.3, color = \"green\")\n",
    "            plt.sca(ax[1])\n",
    "            plt.plot(prediction_residuals, alpha = 0.1, color = \"red\")\n",
    "            #plt.plot(prediction_residuals, alpha = 0.1, color = \"red\")\n",
    "            plt.yscale(\"log\")\n",
    "            \n",
    "        score = prediction_residuals.mean()\n",
    "        return score, pred_y, true_y, estim_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-chester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "losses_l1 = []\n",
    "for l1 in [0.0001, 0.001, 0.01, 0.1, 0]:\n",
    "    score, pred, gt, estim  = optimize(a0 = lambda t: t**2,#-(5./t + t)#-3*t**2\n",
    "                                a1 = lambda t:1 + 0.*t,\n",
    "                                f = lambda t: torch.sin(t),\n",
    "                                n_timepoints = 500,\n",
    "                                regularization = 20,\n",
    "                                l1_reg_strength = l1)\n",
    "    data_point = {\"score\" : float(score), \"l1_reg\" : l1}\n",
    "    losses_l1.append(data_point) #[str(l1)] = (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = pd.DataFrame(losses_l1)\n",
    "sns.barplot(data = df, x = \"l1_reg\", y = \"score\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "losses_l2 = []\n",
    "for l2 in [0, 0.001, 0.01, 0.1, 1, 5, 10, 50, 100, 1000]:\n",
    "    score, pred, gt, estim  = optimize(a0 = lambda t: t**2,#-(5./t + t)#-3*t**2\n",
    "                                a1 = lambda t:1 + 0.*t,\n",
    "                                f = lambda t: torch.sin(t),\n",
    "                                n_timepoints = 50,\n",
    "                                regularization = 20,\n",
    "                                l1_reg_strength = 0.0001)\n",
    "    data_point = {\"score\" : float(score), \"l2_reg\" : l2}\n",
    "    losses_l2.append(data_point) #[str(l1)] = (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(losses_l2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sns.barplot(data = df, x = \"l2_reg\", y = \"score\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "score, pred, gt, estim  = optimize(a0 = lambda t: t**2,#-(5./t + t)#-3*t**2\n",
    "                            a1 = lambda t:1 + 0.*t,\n",
    "                            f = lambda t: torch.sin(t),\n",
    "                            n_timepoints = 500,\n",
    "                            regularization = 5,\n",
    "                            #l1_reg_strength = 0.0001,\n",
    "                            visualize_ = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pred, gt, estim  = optimize(a0 = lambda t: t**2,#-(5./t + t)#-3*t**2\n",
    "                            a1 = lambda t:1 + 0.*t,\n",
    "                            f = lambda t: torch.sin(t),\n",
    "                            n_timepoints = 50,\n",
    "                            #regularization = 0.001,\n",
    "                           wout = \"learned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (14, 4))\n",
    "# for i in range(y.shape[0]):\n",
    "#     plt.plot(gt[:,i], alpha = 0.3, color = \"red\")\n",
    "#     plt.plot(pred[:,i], alpha = 0.3, color = \"blue\")\n",
    "#     plt.plot(estim[:,i], alpha = 0.3, color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y.shape[0]):\n",
    "    plt.plot((y[:,i] - pred[:,i])**2, alpha = 0.3, color = \"red\")\n",
    "plt.yscale(\"log\")\n",
    "    #plt.plot(, alpha = 0.3, color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_s_sdot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dir(locals()):\n",
    "    print(i)\n",
    "    if type(i) == type(hi):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "NDIMZ = 5\n",
    "dir(NDIMZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield val.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print([f for f in globals().values() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-pioneer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
